{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xsMPuuH5L4g"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "#import encoder as enc\n",
    "import generator as gen\n",
    "import discriminator as disc\n",
    "import STL10GrayColor as STLGray\n",
    "import utils as utls\n",
    "import losses\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import lab2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RUcBis81-8Zr",
    "outputId": "c87c70e1-d45a-43d6-ca2b-2552e9d17e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#data\n",
    "transform = transforms.Compose([transforms.Resize(128)])\n",
    "\n",
    "# Load STL10 dataset\n",
    "stl10_trainset = STLGray.STL10GrayColor(root=\"./data\",\n",
    "                              split='train',\n",
    "                              download=True,\n",
    "                              transform=transform)\n",
    "\n",
    "#TODO\n",
    "#train+unlabeled in split\n",
    "\n",
    "#########################\n",
    "# Test TODO:\n",
    "# update in the same time the encoder and the generator\n",
    "# reduce the learning rate after n epochs\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Gtk1Oj45L4m"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 25\n",
    "# z_dim = 256\n",
    "params_loader = {\n",
    "    'batch_size': batch_size,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(stl10_trainset, **params_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2188
    },
    "colab_type": "code",
    "id": "zDfdHqR4HezG",
    "outputId": "c1b537ff-a15a-4f24-9dac-1c94a6696c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratorSeg(\n",
      "  (convert_bw_to_rgb): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "  )\n",
      "  (enc1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (enc2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (enc3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (enc4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (gen4): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (gen3): GenBlock(\n",
      "    (generate): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (gen2): GenBlock(\n",
      "    (generate): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (gen1): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (last): Sequential(\n",
      "    (0): ConvTranspose2d(64, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (attention): SelfAttention(\n",
      "    (query): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax()\n",
      "  )\n",
      ")\n",
      "SADiscriminator(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(2, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.1)\n",
      "    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.1)\n",
      "    (6): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): LeakyReLU(negative_slope=0.1)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): LeakyReLU(negative_slope=0.1)\n",
      "    (10): SelfAttention(\n",
      "      (query): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (key): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (value): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (softmax): Softmax()\n",
      "    )\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = gen.GeneratorSeg(color_ch=2)\n",
    "netD = disc.SADiscriminator(in_dim=2)\n",
    "\n",
    "# TODO init layers of the generator in the class\n",
    "netD.apply(utls.xavier_init_weights)\n",
    "\n",
    "netG.to(device)\n",
    "netD.to(device)\n",
    "\n",
    "# parameters given in the original paper\n",
    "lr_g = 0.0001\n",
    "lr_d = 0.0004\n",
    "\n",
    "betas = (0., 0.9)\n",
    "\n",
    "optimizer_g = Adam(netG.parameters(), lr=lr_g, betas=betas)\n",
    "optimizer_d = Adam(netD.parameters(), lr=lr_d, betas=betas)\n",
    "\n",
    "print(netG)\n",
    "print(netD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4810
    },
    "colab_type": "code",
    "id": "LPjyu32vJInE",
    "outputId": "c3a73146-0266-4aaa-a246-a029e25e706a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Epoch [0/50], iter[0/200], d_out_real: 4.2780, g_out_fake: -0.2344\n",
      "Epoch [0/50], iter[1/200], d_out_real: 1.2425, g_out_fake: -0.1151\n",
      "Epoch [0/50], iter[2/200], d_out_real: 1.2093, g_out_fake: -0.0600\n",
      "Epoch [0/50], iter[3/200], d_out_real: 1.0809, g_out_fake: -0.0226\n",
      "Epoch [0/50], iter[4/200], d_out_real: 1.0396, g_out_fake: 0.0156\n",
      "Epoch [0/50], iter[5/200], d_out_real: 1.0213, g_out_fake: 0.0512\n",
      "Epoch [0/50], iter[6/200], d_out_real: 0.9700, g_out_fake: 0.0690\n",
      "Epoch [0/50], iter[7/200], d_out_real: 0.9799, g_out_fake: 0.1288\n",
      "Epoch [0/50], iter[8/200], d_out_real: 0.9435, g_out_fake: 0.2670\n",
      "Epoch [0/50], iter[9/200], d_out_real: 0.8925, g_out_fake: -0.1701\n",
      "Epoch [0/50], iter[10/200], d_out_real: 1.2882, g_out_fake: 0.0600\n",
      "Epoch [0/50], iter[11/200], d_out_real: 1.0027, g_out_fake: 0.1299\n",
      "Epoch [0/50], iter[12/200], d_out_real: 0.8954, g_out_fake: 0.2377\n",
      "Epoch [0/50], iter[13/200], d_out_real: 0.8034, g_out_fake: 0.5116\n",
      "Epoch [0/50], iter[14/200], d_out_real: 1.4150, g_out_fake: 0.0710\n",
      "Epoch [0/50], iter[15/200], d_out_real: 0.9806, g_out_fake: 0.1491\n",
      "Epoch [0/50], iter[16/200], d_out_real: 0.9108, g_out_fake: 0.2016\n",
      "Epoch [0/50], iter[17/200], d_out_real: 0.8107, g_out_fake: 0.2795\n",
      "Epoch [0/50], iter[18/200], d_out_real: 0.7388, g_out_fake: 0.4472\n",
      "Epoch [0/50], iter[19/200], d_out_real: 0.6780, g_out_fake: 0.8852\n",
      "Epoch [0/50], iter[20/200], d_out_real: 0.2861, g_out_fake: 2.9625\n",
      "Epoch [0/50], iter[21/200], d_out_real: 11.6793, g_out_fake: -0.4155\n",
      "Epoch [0/50], iter[22/200], d_out_real: 1.6318, g_out_fake: -0.1737\n",
      "Epoch [0/50], iter[23/200], d_out_real: 1.2559, g_out_fake: -0.0504\n",
      "Epoch [0/50], iter[24/200], d_out_real: 1.1952, g_out_fake: 0.0369\n",
      "Epoch [0/50], iter[25/200], d_out_real: 0.9906, g_out_fake: 0.0979\n",
      "Epoch [0/50], iter[26/200], d_out_real: 0.9205, g_out_fake: 0.1488\n",
      "Epoch [0/50], iter[27/200], d_out_real: 0.8643, g_out_fake: 0.1995\n",
      "Epoch [0/50], iter[28/200], d_out_real: 0.8094, g_out_fake: 0.2464\n",
      "Epoch [0/50], iter[29/200], d_out_real: 0.7593, g_out_fake: 0.2958\n",
      "Epoch [0/50], iter[30/200], d_out_real: 0.7117, g_out_fake: 0.3543\n",
      "Epoch [0/50], iter[31/200], d_out_real: 0.6902, g_out_fake: 0.3428\n",
      "Epoch [0/50], iter[32/200], d_out_real: 0.6720, g_out_fake: 0.4328\n",
      "Epoch [0/50], iter[33/200], d_out_real: 0.6357, g_out_fake: 0.5459\n",
      "Epoch [0/50], iter[34/200], d_out_real: 0.5003, g_out_fake: 0.6899\n",
      "Epoch [0/50], iter[35/200], d_out_real: 0.3593, g_out_fake: 0.9737\n",
      "Epoch [0/50], iter[36/200], d_out_real: 2.6646, g_out_fake: -0.2436\n",
      "Epoch [0/50], iter[37/200], d_out_real: 1.7923, g_out_fake: 0.2087\n",
      "Epoch [0/50], iter[38/200], d_out_real: 1.0006, g_out_fake: 0.3916\n",
      "Epoch [0/50], iter[39/200], d_out_real: 0.7046, g_out_fake: 0.4977\n",
      "Epoch [0/50], iter[40/200], d_out_real: 0.5360, g_out_fake: 0.6084\n",
      "Epoch [0/50], iter[41/200], d_out_real: 0.4185, g_out_fake: 0.7148\n",
      "Epoch [0/50], iter[42/200], d_out_real: 0.2993, g_out_fake: 0.8646\n",
      "Epoch [0/50], iter[43/200], d_out_real: 0.1648, g_out_fake: 1.0709\n",
      "Epoch [0/50], iter[44/200], d_out_real: 0.0198, g_out_fake: 1.1344\n",
      "Epoch [0/50], iter[45/200], d_out_real: 0.0056, g_out_fake: 1.1495\n",
      "Epoch [0/50], iter[46/200], d_out_real: 0.0068, g_out_fake: 1.1668\n",
      "Epoch [0/50], iter[47/200], d_out_real: 0.0053, g_out_fake: 1.1649\n",
      "Epoch [0/50], iter[48/200], d_out_real: 0.0008, g_out_fake: 1.1821\n",
      "Epoch [0/50], iter[49/200], d_out_real: 0.0071, g_out_fake: 1.2057\n",
      "Epoch [0/50], iter[50/200], d_out_real: 0.0046, g_out_fake: 1.2175\n",
      "Epoch [0/50], iter[51/200], d_out_real: 0.0055, g_out_fake: 1.2434\n",
      "Epoch [0/50], iter[52/200], d_out_real: 0.0047, g_out_fake: 1.2449\n",
      "Epoch [0/50], iter[53/200], d_out_real: 0.0000, g_out_fake: 1.2200\n",
      "Epoch [0/50], iter[54/200], d_out_real: 0.0034, g_out_fake: 1.3480\n",
      "Epoch [0/50], iter[55/200], d_out_real: 0.0000, g_out_fake: 1.3173\n",
      "Epoch [0/50], iter[56/200], d_out_real: 0.0000, g_out_fake: 1.2862\n",
      "Epoch [0/50], iter[57/200], d_out_real: 0.0000, g_out_fake: 1.2557\n",
      "Epoch [0/50], iter[58/200], d_out_real: 0.1040, g_out_fake: 0.0018\n",
      "Epoch [0/50], iter[59/200], d_out_real: 1.5118, g_out_fake: 0.9366\n",
      "Epoch [0/50], iter[60/200], d_out_real: 0.0884, g_out_fake: 1.3344\n",
      "Epoch [0/50], iter[61/200], d_out_real: 0.0000, g_out_fake: 1.3073\n",
      "Epoch [0/50], iter[62/200], d_out_real: 0.0000, g_out_fake: 1.2863\n",
      "Epoch [0/50], iter[63/200], d_out_real: 0.0999, g_out_fake: 1.2410\n",
      "Epoch [0/50], iter[64/200], d_out_real: 0.0983, g_out_fake: 1.1955\n",
      "Epoch [0/50], iter[65/200], d_out_real: 0.0000, g_out_fake: 1.1799\n",
      "Epoch [0/50], iter[66/200], d_out_real: 0.0000, g_out_fake: 1.1576\n",
      "Epoch [0/50], iter[67/200], d_out_real: 0.0000, g_out_fake: 1.1392\n",
      "Epoch [0/50], iter[68/200], d_out_real: 0.0000, g_out_fake: 1.1072\n",
      "Epoch [0/50], iter[69/200], d_out_real: 0.0000, g_out_fake: 1.0829\n",
      "Epoch [0/50], iter[70/200], d_out_real: 0.0000, g_out_fake: 1.0758\n",
      "Epoch [0/50], iter[71/200], d_out_real: 0.0000, g_out_fake: 1.0700\n",
      "Epoch [0/50], iter[72/200], d_out_real: 0.0958, g_out_fake: 1.0624\n",
      "Epoch [0/50], iter[73/200], d_out_real: 0.0000, g_out_fake: 1.0425\n",
      "Epoch [0/50], iter[74/200], d_out_real: 0.0022, g_out_fake: 1.2071\n",
      "Epoch [0/50], iter[75/200], d_out_real: 0.1004, g_out_fake: 1.1393\n",
      "Epoch [0/50], iter[76/200], d_out_real: 0.0614, g_out_fake: 1.0875\n",
      "Epoch [0/50], iter[77/200], d_out_real: 0.0000, g_out_fake: 1.0781\n",
      "Epoch [0/50], iter[78/200], d_out_real: 0.0000, g_out_fake: 1.0693\n",
      "Epoch [0/50], iter[79/200], d_out_real: 0.0051, g_out_fake: 1.2768\n",
      "Epoch [0/50], iter[80/200], d_out_real: 0.0000, g_out_fake: 1.2688\n",
      "Epoch [0/50], iter[81/200], d_out_real: 0.1015, g_out_fake: 1.1849\n",
      "Epoch [0/50], iter[82/200], d_out_real: 0.0000, g_out_fake: 1.1800\n",
      "Epoch [0/50], iter[83/200], d_out_real: 0.0000, g_out_fake: 1.1717\n",
      "Epoch [0/50], iter[84/200], d_out_real: 0.0000, g_out_fake: 1.1675\n",
      "Epoch [0/50], iter[85/200], d_out_real: 0.0000, g_out_fake: 1.1604\n",
      "Epoch [0/50], iter[86/200], d_out_real: 0.0000, g_out_fake: 1.1537\n",
      "Epoch [0/50], iter[87/200], d_out_real: 0.0000, g_out_fake: 1.1465\n",
      "Epoch [0/50], iter[88/200], d_out_real: 0.0000, g_out_fake: 1.1410\n",
      "Epoch [0/50], iter[89/200], d_out_real: 0.0000, g_out_fake: 1.1346\n",
      "Epoch [0/50], iter[90/200], d_out_real: 0.0000, g_out_fake: 1.1254\n",
      "Epoch [0/50], iter[91/200], d_out_real: 0.0000, g_out_fake: 1.1187\n",
      "Epoch [0/50], iter[92/200], d_out_real: 0.0000, g_out_fake: 1.1104\n",
      "Epoch [0/50], iter[93/200], d_out_real: 0.0000, g_out_fake: 1.1029\n",
      "Epoch [0/50], iter[94/200], d_out_real: 0.0012, g_out_fake: 1.2564\n",
      "Epoch [0/50], iter[95/200], d_out_real: 0.0466, g_out_fake: 0.8221\n",
      "Epoch [0/50], iter[96/200], d_out_real: 0.2439, g_out_fake: 2.7456\n",
      "Epoch [0/50], iter[97/200], d_out_real: 4.6858, g_out_fake: 0.7246\n",
      "Epoch [0/50], iter[98/200], d_out_real: 0.4649, g_out_fake: 0.8094\n",
      "Epoch [0/50], iter[99/200], d_out_real: 0.3751, g_out_fake: 0.9280\n",
      "Epoch [0/50], iter[100/200], d_out_real: 0.1388, g_out_fake: 1.0305\n",
      "Epoch [0/50], iter[101/200], d_out_real: 0.1028, g_out_fake: 1.1256\n",
      "Epoch [0/50], iter[102/200], d_out_real: 0.0394, g_out_fake: 1.1952\n",
      "Epoch [0/50], iter[103/200], d_out_real: 0.0166, g_out_fake: 1.2289\n",
      "Epoch [0/50], iter[104/200], d_out_real: 0.0246, g_out_fake: 1.2496\n",
      "Epoch [0/50], iter[105/200], d_out_real: 0.0000, g_out_fake: 1.2392\n",
      "Epoch [0/50], iter[106/200], d_out_real: 0.0000, g_out_fake: 1.2265\n",
      "Epoch [0/50], iter[107/200], d_out_real: 0.1976, g_out_fake: 1.2394\n",
      "Epoch [0/50], iter[108/200], d_out_real: 0.0000, g_out_fake: 1.2309\n",
      "Epoch [0/50], iter[109/200], d_out_real: 0.0971, g_out_fake: 1.2024\n",
      "Epoch [0/50], iter[110/200], d_out_real: 0.0000, g_out_fake: 1.1913\n",
      "Epoch [0/50], iter[111/200], d_out_real: 0.0000, g_out_fake: 1.1769\n",
      "Epoch [0/50], iter[112/200], d_out_real: 0.0000, g_out_fake: 1.1582\n",
      "Epoch [0/50], iter[113/200], d_out_real: 0.0080, g_out_fake: 1.2851\n",
      "Epoch [0/50], iter[114/200], d_out_real: 0.1647, g_out_fake: 1.2211\n",
      "Epoch [0/50], iter[115/200], d_out_real: 0.0000, g_out_fake: 1.2150\n",
      "Epoch [0/50], iter[116/200], d_out_real: 0.0000, g_out_fake: 1.2109\n",
      "Epoch [0/50], iter[117/200], d_out_real: 0.0967, g_out_fake: 1.1783\n",
      "Epoch [0/50], iter[118/200], d_out_real: 0.0000, g_out_fake: 1.1736\n",
      "Epoch [0/50], iter[119/200], d_out_real: 0.0000, g_out_fake: 1.1686\n",
      "Epoch [0/50], iter[120/200], d_out_real: 0.0000, g_out_fake: 1.1630\n",
      "Epoch [0/50], iter[121/200], d_out_real: 0.0000, g_out_fake: 1.1587\n",
      "Epoch [0/50], iter[122/200], d_out_real: 0.0000, g_out_fake: 1.1529\n",
      "Epoch [0/50], iter[123/200], d_out_real: 0.0000, g_out_fake: 1.1478\n",
      "Epoch [0/50], iter[124/200], d_out_real: 0.0000, g_out_fake: 1.1427\n",
      "Epoch [0/50], iter[125/200], d_out_real: 0.0326, g_out_fake: 1.0945\n",
      "Epoch [0/50], iter[126/200], d_out_real: 0.0004, g_out_fake: 1.1680\n",
      "Epoch [0/50], iter[127/200], d_out_real: 0.0960, g_out_fake: 1.1159\n",
      "Epoch [0/50], iter[128/200], d_out_real: 0.0933, g_out_fake: 1.0694\n",
      "Epoch [0/50], iter[129/200], d_out_real: 0.0960, g_out_fake: 1.2503\n",
      "Epoch [0/50], iter[130/200], d_out_real: 0.0000, g_out_fake: 1.2381\n",
      "Epoch [0/50], iter[131/200], d_out_real: 0.0000, g_out_fake: 1.2297\n",
      "Epoch [0/50], iter[132/200], d_out_real: 0.0299, g_out_fake: 1.1835\n",
      "Epoch [0/50], iter[133/200], d_out_real: 0.0933, g_out_fake: 1.1202\n",
      "Epoch [0/50], iter[134/200], d_out_real: 0.0000, g_out_fake: 1.1131\n",
      "Epoch [0/50], iter[135/200], d_out_real: 0.0000, g_out_fake: 1.1070\n",
      "Epoch [0/50], iter[136/200], d_out_real: 0.0000, g_out_fake: 1.0989\n",
      "Epoch [0/50], iter[137/200], d_out_real: 0.0000, g_out_fake: 1.0920\n",
      "Epoch [0/50], iter[138/200], d_out_real: 0.0054, g_out_fake: 1.0400\n",
      "Epoch [0/50], iter[139/200], d_out_real: 0.0382, g_out_fake: 1.7350\n",
      "Epoch [0/50], iter[140/200], d_out_real: 0.0000, g_out_fake: 1.7128\n",
      "Epoch [0/50], iter[141/200], d_out_real: 0.0671, g_out_fake: 1.6260\n",
      "Epoch [0/50], iter[142/200], d_out_real: 0.0000, g_out_fake: 1.6190\n",
      "Epoch [0/50], iter[143/200], d_out_real: 0.1113, g_out_fake: 1.4965\n",
      "Epoch [0/50], iter[144/200], d_out_real: 0.0058, g_out_fake: 1.5689\n",
      "Epoch [0/50], iter[145/200], d_out_real: 0.0000, g_out_fake: 1.5518\n",
      "Epoch [0/50], iter[146/200], d_out_real: 0.0272, g_out_fake: 1.6341\n",
      "Epoch [0/50], iter[147/200], d_out_real: 0.0000, g_out_fake: 1.6255\n",
      "Epoch [0/50], iter[148/200], d_out_real: 0.0000, g_out_fake: 1.6141\n",
      "Epoch [0/50], iter[149/200], d_out_real: 0.0000, g_out_fake: 1.6137\n",
      "Epoch [0/50], iter[150/200], d_out_real: 0.0022, g_out_fake: 1.7356\n",
      "Epoch [0/50], iter[151/200], d_out_real: 0.0000, g_out_fake: 1.7282\n",
      "Epoch [0/50], iter[152/200], d_out_real: 0.1838, g_out_fake: 1.4210\n",
      "Epoch [0/50], iter[153/200], d_out_real: 0.0000, g_out_fake: 1.4144\n",
      "Epoch [0/50], iter[154/200], d_out_real: 0.0000, g_out_fake: 1.4098\n",
      "Epoch [0/50], iter[155/200], d_out_real: 0.0000, g_out_fake: 1.4038\n",
      "Epoch [0/50], iter[156/200], d_out_real: 0.0000, g_out_fake: 1.3979\n",
      "Epoch [0/50], iter[157/200], d_out_real: 0.0000, g_out_fake: 1.3952\n",
      "Epoch [0/50], iter[158/200], d_out_real: 0.0000, g_out_fake: 1.3897\n",
      "Epoch [0/50], iter[159/200], d_out_real: 0.0000, g_out_fake: 1.3866\n",
      "Epoch [0/50], iter[160/200], d_out_real: 0.0000, g_out_fake: 1.3808\n",
      "Epoch [0/50], iter[161/200], d_out_real: 0.2098, g_out_fake: 1.1878\n",
      "Epoch [0/50], iter[162/200], d_out_real: 0.0898, g_out_fake: 1.0643\n",
      "Epoch [0/50], iter[163/200], d_out_real: 0.0000, g_out_fake: 1.0612\n",
      "Epoch [0/50], iter[164/200], d_out_real: 0.0101, g_out_fake: 0.9563\n",
      "Epoch [0/50], iter[165/200], d_out_real: 0.1152, g_out_fake: 1.9731\n",
      "Epoch [0/50], iter[166/200], d_out_real: 0.1332, g_out_fake: 1.7546\n",
      "Epoch [0/50], iter[167/200], d_out_real: 0.0000, g_out_fake: 1.7221\n",
      "Epoch [0/50], iter[168/200], d_out_real: 0.0000, g_out_fake: 1.7084\n",
      "Epoch [0/50], iter[169/200], d_out_real: 0.0000, g_out_fake: 1.6954\n",
      "Epoch [0/50], iter[170/200], d_out_real: 0.0000, g_out_fake: 1.6730\n",
      "Epoch [0/50], iter[171/200], d_out_real: 0.0104, g_out_fake: 1.7688\n",
      "Epoch [0/50], iter[172/200], d_out_real: 0.0000, g_out_fake: 1.7558\n",
      "Epoch [0/50], iter[173/200], d_out_real: 0.0000, g_out_fake: 1.7384\n",
      "Epoch [0/50], iter[174/200], d_out_real: 0.0000, g_out_fake: 1.7421\n",
      "Epoch [0/50], iter[175/200], d_out_real: 0.0000, g_out_fake: 1.7328\n",
      "Epoch [0/50], iter[176/200], d_out_real: 0.1158, g_out_fake: 1.5225\n",
      "Epoch [0/50], iter[177/200], d_out_real: 0.0018, g_out_fake: 1.7223\n",
      "Epoch [0/50], iter[178/200], d_out_real: 0.3812, g_out_fake: 0.9706\n",
      "Epoch [0/50], iter[179/200], d_out_real: 0.2290, g_out_fake: 1.2895\n",
      "Epoch [0/50], iter[180/200], d_out_real: 0.0000, g_out_fake: 1.2817\n",
      "Epoch [0/50], iter[181/200], d_out_real: 0.0000, g_out_fake: 1.2781\n",
      "Epoch [0/50], iter[182/200], d_out_real: 0.0000, g_out_fake: 1.2736\n",
      "Epoch [0/50], iter[183/200], d_out_real: 0.0000, g_out_fake: 1.2700\n",
      "Epoch [0/50], iter[184/200], d_out_real: 0.0000, g_out_fake: 1.2652\n",
      "Epoch [0/50], iter[185/200], d_out_real: 0.0000, g_out_fake: 1.2632\n",
      "Epoch [0/50], iter[186/200], d_out_real: 0.0000, g_out_fake: 1.2586\n",
      "Epoch [0/50], iter[187/200], d_out_real: 0.0000, g_out_fake: 1.2542\n",
      "Epoch [0/50], iter[188/200], d_out_real: 0.0000, g_out_fake: 1.2535\n",
      "Epoch [0/50], iter[189/200], d_out_real: 0.0000, g_out_fake: 1.2462\n",
      "Epoch [0/50], iter[190/200], d_out_real: 0.0943, g_out_fake: 1.1704\n",
      "Epoch [0/50], iter[191/200], d_out_real: 0.0000, g_out_fake: 1.1651\n",
      "Epoch [0/50], iter[192/200], d_out_real: 0.0014, g_out_fake: 1.2267\n",
      "Epoch [0/50], iter[193/200], d_out_real: 0.0000, g_out_fake: 1.2235\n",
      "Epoch [0/50], iter[194/200], d_out_real: 0.0000, g_out_fake: 1.2202\n",
      "Epoch [0/50], iter[195/200], d_out_real: 0.0929, g_out_fake: 1.1330\n",
      "Epoch [0/50], iter[196/200], d_out_real: 0.0000, g_out_fake: 1.1312\n",
      "Epoch [0/50], iter[197/200], d_out_real: 0.0887, g_out_fake: 1.0515\n",
      "Epoch [0/50], iter[198/200], d_out_real: 0.0012, g_out_fake: 1.2515\n",
      "Epoch [0/50], iter[199/200], d_out_real: 0.0929, g_out_fake: 1.1551\n",
      "epoch : 1\n",
      "Epoch [1/50], iter[0/200], d_out_real: 0.0000, g_out_fake: 1.1551\n",
      "Epoch [1/50], iter[1/200], d_out_real: 0.0000, g_out_fake: 1.1531\n",
      "Epoch [1/50], iter[2/200], d_out_real: 0.1765, g_out_fake: 0.9901\n",
      "Epoch [1/50], iter[3/200], d_out_real: 0.0106, g_out_fake: 1.7071\n",
      "Epoch [1/50], iter[4/200], d_out_real: 0.0000, g_out_fake: 1.6972\n",
      "Epoch [1/50], iter[5/200], d_out_real: 0.0439, g_out_fake: 1.6174\n",
      "Epoch [1/50], iter[6/200], d_out_real: 0.0035, g_out_fake: 1.7233\n",
      "Epoch [1/50], iter[7/200], d_out_real: 0.0036, g_out_fake: 1.5377\n",
      "Epoch [1/50], iter[8/200], d_out_real: 0.1660, g_out_fake: 1.6379\n",
      "Epoch [1/50], iter[9/200], d_out_real: 0.0000, g_out_fake: 1.6251\n",
      "Epoch [1/50], iter[10/200], d_out_real: 0.0000, g_out_fake: 1.6188\n",
      "Epoch [1/50], iter[11/200], d_out_real: 0.0927, g_out_fake: 1.5059\n",
      "Epoch [1/50], iter[12/200], d_out_real: 0.0000, g_out_fake: 1.4978\n",
      "Epoch [1/50], iter[13/200], d_out_real: 0.0000, g_out_fake: 1.4881\n",
      "Epoch [1/50], iter[14/200], d_out_real: 0.0000, g_out_fake: 1.4789\n",
      "Epoch [1/50], iter[15/200], d_out_real: 0.0000, g_out_fake: 1.4692\n",
      "Epoch [1/50], iter[16/200], d_out_real: 0.1052, g_out_fake: 1.3428\n",
      "Epoch [1/50], iter[17/200], d_out_real: 0.0000, g_out_fake: 1.3316\n",
      "Epoch [1/50], iter[18/200], d_out_real: 0.0000, g_out_fake: 1.3250\n",
      "Epoch [1/50], iter[19/200], d_out_real: 0.0989, g_out_fake: 1.2170\n",
      "Epoch [1/50], iter[20/200], d_out_real: 0.0000, g_out_fake: 1.2115\n",
      "Epoch [1/50], iter[21/200], d_out_real: 0.0000, g_out_fake: 1.2065\n",
      "Epoch [1/50], iter[22/200], d_out_real: 0.0000, g_out_fake: 1.2021\n",
      "Epoch [1/50], iter[23/200], d_out_real: 0.0000, g_out_fake: 1.1970\n",
      "Epoch [1/50], iter[24/200], d_out_real: 0.1876, g_out_fake: 1.0209\n",
      "Epoch [1/50], iter[25/200], d_out_real: 0.0000, g_out_fake: 1.0153\n",
      "Epoch [1/50], iter[26/200], d_out_real: 0.0000, g_out_fake: 1.0119\n",
      "Epoch [1/50], iter[27/200], d_out_real: 0.0004, g_out_fake: 1.2663\n",
      "Epoch [1/50], iter[28/200], d_out_real: 0.0000, g_out_fake: 1.2651\n",
      "Epoch [1/50], iter[29/200], d_out_real: 0.0000, g_out_fake: 1.2643\n",
      "Epoch [1/50], iter[30/200], d_out_real: 0.0000, g_out_fake: 1.2637\n",
      "Epoch [1/50], iter[31/200], d_out_real: 0.0693, g_out_fake: 1.1647\n",
      "Epoch [1/50], iter[32/200], d_out_real: 0.0000, g_out_fake: 1.1617\n",
      "Epoch [1/50], iter[33/200], d_out_real: 0.0884, g_out_fake: 1.0480\n",
      "Epoch [1/50], iter[34/200], d_out_real: 0.0000, g_out_fake: 1.0401\n",
      "Epoch [1/50], iter[35/200], d_out_real: 0.0000, g_out_fake: 1.0333\n",
      "Epoch [1/50], iter[36/200], d_out_real: 0.0000, g_out_fake: 1.0222\n",
      "Epoch [1/50], iter[37/200], d_out_real: 0.0012, g_out_fake: 1.5799\n",
      "Epoch [1/50], iter[38/200], d_out_real: 0.0000, g_out_fake: 1.5751\n",
      "Epoch [1/50], iter[39/200], d_out_real: 0.0000, g_out_fake: 1.5726\n",
      "Epoch [1/50], iter[40/200], d_out_real: 0.0000, g_out_fake: 1.5711\n",
      "Epoch [1/50], iter[41/200], d_out_real: 0.0000, g_out_fake: 1.5694\n",
      "Epoch [1/50], iter[42/200], d_out_real: 0.0000, g_out_fake: 1.5687\n",
      "Epoch [1/50], iter[43/200], d_out_real: 0.0000, g_out_fake: 1.5656\n",
      "Epoch [1/50], iter[44/200], d_out_real: 0.0000, g_out_fake: 1.5635\n",
      "Epoch [1/50], iter[45/200], d_out_real: 0.0000, g_out_fake: 1.5615\n",
      "Epoch [1/50], iter[46/200], d_out_real: 0.0000, g_out_fake: 1.5596\n",
      "Epoch [1/50], iter[47/200], d_out_real: 0.0000, g_out_fake: 1.5578\n",
      "Epoch [1/50], iter[48/200], d_out_real: 0.0000, g_out_fake: 1.5561\n",
      "Epoch [1/50], iter[49/200], d_out_real: 0.0000, g_out_fake: 1.5559\n",
      "Epoch [1/50], iter[50/200], d_out_real: 0.0000, g_out_fake: 1.5560\n",
      "Epoch [1/50], iter[51/200], d_out_real: 0.0000, g_out_fake: 1.5525\n",
      "Epoch [1/50], iter[52/200], d_out_real: 0.0000, g_out_fake: 1.5507\n",
      "Epoch [1/50], iter[53/200], d_out_real: 0.0000, g_out_fake: 1.5492\n",
      "Epoch [1/50], iter[54/200], d_out_real: 0.0000, g_out_fake: 1.5478\n",
      "Epoch [1/50], iter[55/200], d_out_real: 0.0000, g_out_fake: 1.5468\n",
      "Epoch [1/50], iter[56/200], d_out_real: 0.0000, g_out_fake: 1.5455\n",
      "Epoch [1/50], iter[57/200], d_out_real: 0.0000, g_out_fake: 1.5446\n",
      "Epoch [1/50], iter[58/200], d_out_real: 0.0000, g_out_fake: 1.5434\n",
      "Epoch [1/50], iter[59/200], d_out_real: 0.0000, g_out_fake: 1.5421\n",
      "Epoch [1/50], iter[60/200], d_out_real: 0.0000, g_out_fake: 1.5410\n",
      "Epoch [1/50], iter[61/200], d_out_real: 0.0000, g_out_fake: 1.5401\n",
      "Epoch [1/50], iter[62/200], d_out_real: 0.0000, g_out_fake: 1.5388\n",
      "Epoch [1/50], iter[63/200], d_out_real: 0.1027, g_out_fake: 1.1185\n",
      "Epoch [1/50], iter[64/200], d_out_real: 0.0847, g_out_fake: 0.9350\n",
      "Epoch [1/50], iter[65/200], d_out_real: 0.0669, g_out_fake: 1.5338\n",
      "Epoch [1/50], iter[66/200], d_out_real: 0.0000, g_out_fake: 1.5280\n",
      "Epoch [1/50], iter[67/200], d_out_real: 0.0000, g_out_fake: 1.5251\n",
      "Epoch [1/50], iter[68/200], d_out_real: 0.0000, g_out_fake: 1.5224\n",
      "Epoch [1/50], iter[69/200], d_out_real: 0.0000, g_out_fake: 1.5198\n",
      "Epoch [1/50], iter[70/200], d_out_real: 0.0000, g_out_fake: 1.5180\n",
      "Epoch [1/50], iter[71/200], d_out_real: 0.0000, g_out_fake: 1.5162\n",
      "Epoch [1/50], iter[72/200], d_out_real: 0.1009, g_out_fake: 1.4055\n",
      "Epoch [1/50], iter[73/200], d_out_real: 0.0000, g_out_fake: 1.4034\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "wass_loss = False\n",
    "\n",
    "def disc_hinge_loss(netD, real_data, fake_data):\n",
    "    # Train with real\n",
    "    d_out_real = netD(real_data)\n",
    "    \n",
    "    # Train with fake\n",
    "    d_out_fake = netD(fake_data)\n",
    "    \n",
    "    # adversial hinge loss\n",
    "    d_loss_real = nn.ReLU()(1.0 - d_out_real).mean()\n",
    "    d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    return d_loss\n",
    "\n",
    "def gen_hinge_loss(netD, fake_data):\n",
    "    loss = -netD(fake_data).mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch :\", epoch)\n",
    "\n",
    "    for idx, (img_g, img_c) in enumerate(train_loader):\n",
    "        \n",
    "        img_g = img_g.to(device)\n",
    "        img_c = img_c.to(device)\n",
    "\n",
    "        # The last batch hasn't the same batch size so skip it\n",
    "        bs, *_ = img_g.shape\n",
    "        if bs != batch_size:\n",
    "            continue\n",
    "\n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "\n",
    "        # Create fake colors\n",
    "        fakes = netG(img_g)\n",
    "        \n",
    "        if wass_loss:\n",
    "            d_loss = losses.dis_loss(netD, img_c, fakes.detach())\n",
    "        else:\n",
    "            d_loss = disc_hinge_loss(netD, img_c, fakes.detach())\n",
    "            \n",
    "        m_d_loss = d_loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        netD.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Release the gpu memory\n",
    "        del d_loss\n",
    "        \n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "        \n",
    "        if wass_loss:\n",
    "            g_loss = losses.gen_loss(netD, fakes)\n",
    "        else:\n",
    "            g_loss = gen_hinge_loss(netD, fakes)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        netG.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        m_g_loss = g_loss.item()\n",
    "        \n",
    "\n",
    "        print(f\"Epoch [{epoch}/{n_epochs}], \"\n",
    "              f\"iter[{idx}/{len(train_loader)}], \"\n",
    "              f\"d_out_real: {m_d_loss:.4f}, \"\n",
    "              f\"g_out_fake: {m_g_loss:.4f}\")\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            \n",
    "            grayscale = torch.squeeze(img_g.detach())\n",
    "            img_display = utls.convert_lab2rgb(grayscale,\n",
    "                                               fakes.detach())\n",
    "            vutils.save_image(img_display.detach(),\n",
    "                              f'./l_{epoch}_epoch_{idx}.png',\n",
    "                              normalize=True)\n",
    "            \n",
    "        # Release the gpu memory\n",
    "        del fakes, g_loss\n",
    "            \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTC2r4gf5L4q"
   },
   "outputs": [],
   "source": [
    "load_old_state = False\n",
    "\n",
    "# Create model\n",
    "encoder = enc.Encoder(z_dim=z_dim)\n",
    "\n",
    "generator = gen.Generator(z_dim=z_dim, init_depth=512)\n",
    "\n",
    "discriminator = disc.Discriminator(max_depth=512)\n",
    "\n",
    "if load_old_state:\n",
    "    # Caution: I saved models with wrong name !!!!!!!!\n",
    "    checkpoint = torch.load('_weights_8_iteration_600.pth')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "    \n",
    "else:\n",
    "    generator.apply(utls.weights_init)\n",
    "    discriminator.apply(utls.weights_init)\n",
    "    \n",
    "# Load model on GPU\n",
    "encoder = encoder.to(device)\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "\n",
    "optimizer_params = {\n",
    "    'lr': 0.0001,\n",
    "    'betas':(0.5, 0.999),\n",
    "    'weight_decay': 1e-4\n",
    "}\n",
    "\n",
    "enc_loss = nn.MSELoss()\n",
    "\n",
    "if load_old_state:\n",
    "    optimizer_e.load_state_dict(checkpoint['optimizer_e_state_dict'])\n",
    "    optimizer_g.load_state_dict(checkpoint['optimizer_g_state_dict'])\n",
    "    optimizer_d.load_state_dict(checkpoint['optimizer_d_state_dict'])\n",
    "else:\n",
    "    optimizer_e = torch.optim.Adam(encoder.parameters(), **optimizer_params)\n",
    "    optimizer_g = torch.optim.Adam(generator.parameters(), **optimizer_params)\n",
    "    optimizer_d = torch.optim.Adam(discriminator.parameters(), **optimizer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RuZvo_asaOO"
   },
   "outputs": [],
   "source": [
    "print(encoder)\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvId0UyHUR9p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICjCd9RTqZrc"
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"epoch :\", epoch)\n",
    "\n",
    "    for i, (img_g, img_c) in enumerate(train_loader):\n",
    "        \n",
    "        img_g = img_g.to(device)\n",
    "        img_c = img_c.to(device)\n",
    "# \n",
    "        bs, *_ = img_g.shape\n",
    "        if bs != batch_size:\n",
    "            continue\n",
    "\n",
    "\n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "        img_features = encoder(img_g)\n",
    "\n",
    "        img_colorized = generator(img_features.detach())\n",
    "\n",
    "        loss_d = losses.dis_loss(discriminator, img_c, img_colorized.detach())\n",
    "\n",
    "        #bp\n",
    "        discriminator.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        #######################\n",
    "        # Train Generator #\n",
    "        #######################\n",
    "        \n",
    "        #img_colorized = generator(img_features) #re attach ?\n",
    "        \n",
    "        loss_g = losses.gen_loss(discriminator, img_colorized)\n",
    "        \n",
    "        #bp\n",
    "        generator.zero_grad()     \n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        #######################\n",
    "        # Train Encoder #\n",
    "        #######################\n",
    "        \n",
    "        #TODO BETTER WAY/optimizing img_colorized without detach\n",
    "        #img_features = encoder(img_g)\n",
    "\n",
    "        img_colorized = generator(img_features)\n",
    "        \n",
    "        loss_e = enc_loss(img_colorized, img_c)\n",
    "        \n",
    "        #bp\n",
    "        encoder.zero_grad()\n",
    "        loss_e.backward()\n",
    "        optimizer_e.step()\n",
    "        \n",
    "        #printing shit\n",
    "        if (i%10 == 0) :\n",
    "            print(\"iteration \", i, \"out of \", len(train_loader.dataset)//batch_size,\n",
    "                  \"\\terrD : \", round(loss_d.item(),3), \"\\terrG : \", round(loss_g.item(),3), \"\\terrE : \", round(loss_e.item(), 3))\n",
    "        \n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            #img_features = encoder(img_g)\n",
    "            #img_colorized = generator(img_features)\n",
    "            img_display = utls.convert_lab2rgb(img_g, img_colorized.detach())\n",
    "            \n",
    "            vutils.save_image(img_display,\n",
    "                              f\"___epoch_{epoch}.png\",\n",
    "                              nrow=5,\n",
    "                              normalize=True)\n",
    "            print(\">plotted shit\")        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjlIQhn25L45"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "\n",
    "axs[0].set_title(\"All Losses\")\n",
    "axs[0].set_xlabel(\"iterations\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].plot(G_losses,label=\"G\")\n",
    "axs[0].plot(D_losses,label=\"D\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"After 1000 iterations\")\n",
    "axs[1].set_xlabel(\"iterations\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].plot(G_losses[1000:],label=\"G\")\n",
    "axs[1].plot(D_losses[1000:],label=\"D\")\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mN0vP_G8OSNi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
