{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvtRLlUBRT8W"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "\n",
    "# from spectral import SpectralNorm\n",
    "\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ki6kV_XVShLe",
    "outputId": "f86c1758-bc75-401b-bdd3-c04cc21afc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load STL10 dataset\n",
    "# cifar10_dset = dsets.CIFAR10(root=\"./data\",\n",
    "#                              train=True,\n",
    "#                              download=True,\n",
    "#                              transform=transform)\n",
    "\n",
    "stl10_dtset = dsets.STL10(root=\"./data\",\n",
    "                          download=True,\n",
    "                          split='train+unlabeled',\n",
    "                          transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3DGOtWGTJZY"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 16\n",
    "\n",
    "params_loader = {\n",
    "    'batch_size': batch_size,\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(stl10_dtset, **params_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6YNb0fZOD5i"
   },
   "outputs": [],
   "source": [
    "class GenBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, nb_conv_layers):\n",
    "        super(_DecoderBlock, self).__init__()\n",
    "        middle_channels = in_channels // 2\n",
    "        \n",
    "        layers = [\n",
    "            sn_convT2d(in_channels, in_channels, kernel_size=2, stride=2),\n",
    "            sn_conv2d(in_channels, middle_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(middle_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        layers += [\n",
    "            sn_conv2d(middle_channels, middle_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(middle_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ] * (num_conv_layers - 2)\n",
    "        layers += [\n",
    "            sn_conv2d(middle_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        self.generate = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generate(x)\n",
    "\n",
    "class GeneratorSeg(nn.Module):\n",
    "    def __init__(self, color_ch=2):\n",
    "        super(SegNet, self).__init__()\n",
    "        # TODO: check nb channels in vgg\n",
    "        \n",
    "        vgg = models.vgg19_bn(pretrained=True)\n",
    "        \n",
    "        features = list(vgg.features.children())\n",
    "        self.enc1 = nn.Sequential(*features[:7])\n",
    "        self.enc2 = nn.Sequential(*features[7:14])\n",
    "        self.enc3 = nn.Sequential(*features[14:27])\n",
    "        self.enc4 = nn.Sequential(*features[27:40])\n",
    "        self.enc5 = nn.Sequential(*features[40:])\n",
    "        \n",
    "        self.gen5 = nn.Sequential(\n",
    "            *([sn_convT2d(512, 512, kernel_size=2, stride=2)]+\n",
    "              [sn_conv2d(512, 512),\n",
    "              nn.BatchNorm2d(512),\n",
    "              nn.ReLU(True)]*4)\n",
    "        )\n",
    "        self.gen4 = GenBlock(1024, 256, 4)\n",
    "        self.gen3 = GenBlock(512, 128, 4)\n",
    "        self.gen2 = GenBlock(256, 64, 2)\n",
    "        self.gen1 = GenBlock(128, color_ch, 2)\n",
    "        \n",
    "        self.attention1 = SelfAttention(128)\n",
    "        self.attention2 = SelfAttention(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.enc5(enc4)\n",
    "        \n",
    "        gen5 = self.gen5(enc5)\n",
    "        gen4 = self.gen4(torch.cat([enc4, dec5], 1))\n",
    "        gen3 = self.gen3(torch.cat([enc3, dec4], 1))\n",
    "        gen3 = self.attention1(gen3)\n",
    "        # Maybe should apply the attention layer on the enc\n",
    "        # enc2 = self.attention1(enc2)\n",
    "        gen2 = self.gen2(torch.cat([enc2, dec3], 1))\n",
    "        gen2 = self.attention2(gen2)\n",
    "        gen1 = self.gen1(torch.cat([enc1, dec2], 1))\n",
    "        return dec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVAYCpJ_V4aj"
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    bs, ch, width, height = x.shape\n",
    "    \n",
    "    return x.view(bs, -1, width*height)\n",
    "\n",
    "def sn_conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
    "    return spectral_norm(nn.Conv2d(in_channels,\n",
    "                                   out_channels,\n",
    "                                   kernel_size,\n",
    "                                   stride,\n",
    "                                   padding))\n",
    "\n",
    "def sn_convT2d(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return spectral_norm(nn.ConvTranspose2d(in_channels,\n",
    "                                            out_channels,\n",
    "                                            kernel_size,\n",
    "                                            stride,\n",
    "                                            padding))\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, ch_in, sq_fact=8):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        self.ch_in = ch_in\n",
    "        self.query = sn_conv2d(self.ch_in, self.ch_in//sq_fact, 1)\n",
    "        self.key = sn_conv2d(self.ch_in, self.ch_in//sq_fact, 1)\n",
    "        self.value = sn_conv2d(self.ch_in, self.ch_in, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_shape = x.shape\n",
    "        # print(x_shape)\n",
    "        \n",
    "        proj_query = flatten(self.query(x)).permute(0, 2, 1)\n",
    "        proj_key = flatten(self.key(x))\n",
    "        proj_value = flatten(self.value(x))\n",
    "        # print(f\"query: {proj_query.shape}\")\n",
    "        # print(f\"key: {proj_key.shape}\")\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        # print(\"energy\", energy.shape)\n",
    "        attention = self.softmax(energy)\n",
    "        \n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        # print(out.shape)\n",
    "        out = out.view(*x_shape)\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBCmWfvKa0d2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim=3, img_size=64,conv_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.img_size = img_size\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            sn_conv2d(self.in_dim, self.conv_dim, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            sn_conv2d(self.conv_dim, self.conv_dim*2, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            sn_conv2d(self.conv_dim*2, self.conv_dim*4, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            sn_conv2d(self.conv_dim*4, self.conv_dim*4, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            # SelfAttention(256),\n",
    "            # sn_conv2d(self.conv_dim*4, self.conv_dim*8, 4, 2, 1),\n",
    "            # nn.LeakyReLU(0.1),\n",
    "            # \n",
    "            # SelfAttention(512),\n",
    "            # nn.Conv2d(self.conv_dim*8, 1, 4)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            sn_conv2d(self.conv_dim*4, self.conv_dim*8, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(self.conv_dim*8, 1, 4)\n",
    "        )\n",
    "        \n",
    "        # TODO: change dynamicly the channels size\n",
    "        self.attention1 = SelfAttention(256)\n",
    "        self.attention2 = SelfAttention(512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = self.attention1(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.attention2(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        # out = self.layers(x)\n",
    "        \n",
    "        return out.squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf74Sb_We6oG"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_dim=100, conv_dim=64, dim_out=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.conv_dim = conv_dim\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            sn_convT2d(z_dim, conv_dim*8, 4),\n",
    "            nn.BatchNorm2d(conv_dim*8),\n",
    "            nn.ReLU(),\n",
    "            sn_convT2d(conv_dim*8, conv_dim*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(conv_dim*4),\n",
    "            nn.ReLU(),\n",
    "            sn_convT2d(conv_dim*4, conv_dim*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(conv_dim*2),\n",
    "            nn.ReLU(),\n",
    "            sn_convT2d(conv_dim*2, conv_dim*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(conv_dim*2),\n",
    "            nn.ReLU(),\n",
    "            # SelfAttention(128),\n",
    "            # sn_convT2d(conv_dim*2, conv_dim, 4, 2, 1),\n",
    "            # nn.BatchNorm2d(conv_dim),\n",
    "            # nn.ReLU(),\n",
    "            # SelfAttention(64),\n",
    "            # nn.ConvTranspose2d(conv_dim, dim_out, 4, 2, 1),\n",
    "            # nn.Tanh()\n",
    "            \n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            sn_convT2d(conv_dim*2, conv_dim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(conv_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(conv_dim, dim_out, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.attention1 = SelfAttention(128)\n",
    "        self.attention2 = SelfAttention(64)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # bs, ch, *_ = z.shape\n",
    "        # z = z.view(bs, ch, 1, 1)\n",
    "        \n",
    "        out = self.layers(z)\n",
    "        out = self.attention1(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.attention2(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        # out = self.layers(z)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGTAdUkZAz9h"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSg04Avoif9j"
   },
   "outputs": [],
   "source": [
    "# Init\n",
    "z_dim = 128\n",
    "\n",
    "netG = Generator(z_dim=z_dim).to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "netG.apply(init_weights)\n",
    "netD.apply(init_weights)\n",
    "\n",
    "# parameters given in the original paper\n",
    "lr_g = 0.0001\n",
    "lr_d = 0.0004\n",
    "\n",
    "betas = (0., 0.9)\n",
    "\n",
    "optimizer_g = Adam(netG.parameters(), lr=lr_g, betas=betas)\n",
    "optimizer_d = Adam(netD.parameters(), lr=lr_d, betas=betas)\n",
    "\n",
    "# loss_c = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, z_dim, 1, 1, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1771
    },
    "colab_type": "code",
    "id": "E-jdZKcEwRqS",
    "outputId": "4678f6cd-b0ad-408d-ebcb-9bf230d99d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/40], iter[0/6563], d_out_real: 1.0201, g_out_fake: -0.1283\n",
      "Epoch [0/40], iter[100/6563], d_out_real: 0.0000, g_out_fake: 1.6002\n",
      "Epoch [0/40], iter[200/6563], d_out_real: 0.3008, g_out_fake: 1.7927\n",
      "Epoch [0/40], iter[300/6563], d_out_real: 0.0606, g_out_fake: 1.3476\n",
      "Epoch [0/40], iter[400/6563], d_out_real: 0.0168, g_out_fake: 1.4809\n",
      "Epoch [0/40], iter[500/6563], d_out_real: 0.6709, g_out_fake: 0.5638\n",
      "Epoch [0/40], iter[600/6563], d_out_real: 0.8023, g_out_fake: 0.6284\n",
      "Epoch [0/40], iter[700/6563], d_out_real: 0.8316, g_out_fake: 0.6061\n",
      "Epoch [0/40], iter[800/6563], d_out_real: 0.4789, g_out_fake: 0.1009\n",
      "Epoch [0/40], iter[900/6563], d_out_real: 0.6670, g_out_fake: 1.6214\n",
      "Epoch [0/40], iter[1000/6563], d_out_real: 0.6209, g_out_fake: 1.1829\n",
      "Epoch [0/40], iter[1100/6563], d_out_real: 0.4360, g_out_fake: 1.2441\n",
      "Epoch [0/40], iter[1200/6563], d_out_real: 0.2373, g_out_fake: 1.8430\n",
      "Epoch [0/40], iter[1300/6563], d_out_real: 0.8807, g_out_fake: 0.8769\n",
      "Epoch [0/40], iter[1400/6563], d_out_real: 0.4317, g_out_fake: 0.9766\n",
      "Epoch [0/40], iter[1500/6563], d_out_real: 1.0183, g_out_fake: 1.2100\n",
      "Epoch [0/40], iter[1600/6563], d_out_real: 0.6579, g_out_fake: 1.5297\n",
      "Epoch [0/40], iter[1700/6563], d_out_real: 0.9260, g_out_fake: 0.8334\n",
      "Epoch [0/40], iter[1800/6563], d_out_real: 1.2539, g_out_fake: 0.9285\n",
      "Epoch [0/40], iter[1900/6563], d_out_real: 1.0773, g_out_fake: 0.9033\n",
      "Epoch [0/40], iter[2000/6563], d_out_real: 0.6605, g_out_fake: 0.9011\n",
      "Epoch [0/40], iter[2100/6563], d_out_real: 0.8377, g_out_fake: 1.0843\n",
      "Epoch [0/40], iter[2200/6563], d_out_real: 0.5570, g_out_fake: 0.8699\n",
      "Epoch [0/40], iter[2300/6563], d_out_real: 1.8536, g_out_fake: 1.0111\n",
      "Epoch [0/40], iter[2400/6563], d_out_real: 0.2653, g_out_fake: 1.6356\n",
      "Epoch [0/40], iter[2500/6563], d_out_real: 0.8423, g_out_fake: 0.8354\n",
      "Epoch [0/40], iter[2600/6563], d_out_real: 1.1004, g_out_fake: -0.5870\n",
      "Epoch [0/40], iter[2700/6563], d_out_real: 1.6911, g_out_fake: 0.5158\n",
      "Epoch [0/40], iter[2800/6563], d_out_real: 1.2351, g_out_fake: 0.7501\n",
      "Epoch [0/40], iter[2900/6563], d_out_real: 0.9802, g_out_fake: 1.0244\n",
      "Epoch [0/40], iter[3000/6563], d_out_real: 0.9653, g_out_fake: 1.1384\n",
      "Epoch [0/40], iter[3100/6563], d_out_real: 0.9760, g_out_fake: -0.5662\n",
      "Epoch [0/40], iter[3200/6563], d_out_real: 0.9308, g_out_fake: 0.7967\n",
      "Epoch [0/40], iter[3300/6563], d_out_real: 0.9575, g_out_fake: 0.6789\n",
      "Epoch [0/40], iter[3400/6563], d_out_real: 0.6797, g_out_fake: 1.0626\n",
      "Epoch [0/40], iter[3500/6563], d_out_real: 1.2558, g_out_fake: 0.7917\n",
      "Epoch [0/40], iter[3600/6563], d_out_real: 1.0019, g_out_fake: 1.2571\n",
      "Epoch [0/40], iter[3700/6563], d_out_real: 0.9778, g_out_fake: 0.2884\n",
      "Epoch [0/40], iter[3800/6563], d_out_real: 1.2132, g_out_fake: 0.3970\n",
      "Epoch [0/40], iter[3900/6563], d_out_real: 0.4310, g_out_fake: 1.2172\n",
      "Epoch [0/40], iter[4000/6563], d_out_real: 0.7774, g_out_fake: 0.8700\n",
      "Epoch [0/40], iter[4100/6563], d_out_real: 1.4112, g_out_fake: 0.6530\n",
      "Epoch [0/40], iter[4200/6563], d_out_real: 0.8082, g_out_fake: 1.0889\n",
      "Epoch [0/40], iter[4300/6563], d_out_real: 0.6115, g_out_fake: 0.9595\n",
      "Epoch [0/40], iter[4400/6563], d_out_real: 0.2452, g_out_fake: 1.2315\n",
      "Epoch [0/40], iter[4500/6563], d_out_real: 0.3315, g_out_fake: 1.4946\n",
      "Epoch [0/40], iter[4600/6563], d_out_real: 0.6498, g_out_fake: 1.2490\n",
      "Epoch [0/40], iter[4700/6563], d_out_real: 1.0901, g_out_fake: 0.2497\n",
      "Epoch [0/40], iter[4800/6563], d_out_real: 1.1072, g_out_fake: 0.9387\n",
      "Epoch [0/40], iter[4900/6563], d_out_real: 0.4677, g_out_fake: 1.0228\n",
      "Epoch [0/40], iter[5000/6563], d_out_real: 0.9751, g_out_fake: 1.1951\n",
      "Epoch [0/40], iter[5100/6563], d_out_real: 1.7321, g_out_fake: 0.7428\n",
      "Epoch [0/40], iter[5200/6563], d_out_real: 0.5227, g_out_fake: 1.0556\n",
      "Epoch [0/40], iter[5300/6563], d_out_real: 1.2206, g_out_fake: 0.8074\n",
      "Epoch [0/40], iter[5400/6563], d_out_real: 1.1266, g_out_fake: 0.7408\n",
      "Epoch [0/40], iter[5500/6563], d_out_real: 0.5120, g_out_fake: 1.4520\n",
      "Epoch [0/40], iter[5600/6563], d_out_real: 0.6270, g_out_fake: 0.9488\n",
      "Epoch [0/40], iter[5700/6563], d_out_real: 0.6652, g_out_fake: 0.9653\n",
      "Epoch [0/40], iter[5800/6563], d_out_real: 0.7556, g_out_fake: 1.0646\n",
      "Epoch [0/40], iter[5900/6563], d_out_real: 0.8226, g_out_fake: 0.6008\n",
      "Epoch [0/40], iter[6000/6563], d_out_real: 1.1452, g_out_fake: 0.5606\n",
      "Epoch [0/40], iter[6100/6563], d_out_real: 1.0477, g_out_fake: 0.2825\n",
      "Epoch [0/40], iter[6200/6563], d_out_real: 0.6237, g_out_fake: 0.9414\n",
      "Epoch [0/40], iter[6300/6563], d_out_real: 0.8072, g_out_fake: 1.0173\n",
      "Epoch [0/40], iter[6400/6563], d_out_real: 0.3441, g_out_fake: 1.1903\n",
      "Epoch [0/40], iter[6500/6563], d_out_real: 0.6232, g_out_fake: 1.6151\n",
      "Epoch [1/40], iter[0/6563], d_out_real: 0.1158, g_out_fake: 1.2580\n",
      "Epoch [1/40], iter[100/6563], d_out_real: 0.6280, g_out_fake: 0.7590\n",
      "Epoch [1/40], iter[200/6563], d_out_real: 1.1828, g_out_fake: 0.0251\n",
      "Epoch [1/40], iter[300/6563], d_out_real: 1.1006, g_out_fake: 0.7953\n",
      "Epoch [1/40], iter[400/6563], d_out_real: 0.3758, g_out_fake: 1.3050\n",
      "Epoch [1/40], iter[500/6563], d_out_real: 0.8870, g_out_fake: 0.5422\n",
      "Epoch [1/40], iter[600/6563], d_out_real: 0.9236, g_out_fake: 0.9320\n",
      "Epoch [1/40], iter[700/6563], d_out_real: 0.9375, g_out_fake: 0.8082\n",
      "Epoch [1/40], iter[800/6563], d_out_real: 0.2861, g_out_fake: 1.5439\n",
      "Epoch [1/40], iter[900/6563], d_out_real: 1.3999, g_out_fake: 0.5390\n",
      "Epoch [1/40], iter[1000/6563], d_out_real: 0.8266, g_out_fake: 0.6628\n",
      "Epoch [1/40], iter[1100/6563], d_out_real: 0.5879, g_out_fake: 0.8978\n",
      "Epoch [1/40], iter[1200/6563], d_out_real: 0.7698, g_out_fake: 0.5069\n",
      "Epoch [1/40], iter[1300/6563], d_out_real: 0.2190, g_out_fake: 1.4408\n",
      "Epoch [1/40], iter[1400/6563], d_out_real: 0.3568, g_out_fake: 1.1235\n",
      "Epoch [1/40], iter[1500/6563], d_out_real: 1.1047, g_out_fake: 1.0522\n",
      "Epoch [1/40], iter[1600/6563], d_out_real: 0.9522, g_out_fake: 0.3414\n",
      "Epoch [1/40], iter[1700/6563], d_out_real: 1.4630, g_out_fake: 0.0715\n",
      "Epoch [1/40], iter[1800/6563], d_out_real: 0.4610, g_out_fake: 1.1768\n",
      "Epoch [1/40], iter[1900/6563], d_out_real: 1.2112, g_out_fake: 0.4296\n",
      "Epoch [1/40], iter[2000/6563], d_out_real: 0.6551, g_out_fake: 0.8683\n",
      "Epoch [1/40], iter[2100/6563], d_out_real: 0.5458, g_out_fake: 1.2012\n",
      "Epoch [1/40], iter[2200/6563], d_out_real: 0.3542, g_out_fake: 1.2741\n",
      "Epoch [1/40], iter[2300/6563], d_out_real: 0.6127, g_out_fake: 1.5252\n",
      "Epoch [1/40], iter[2400/6563], d_out_real: 0.9589, g_out_fake: 0.3337\n",
      "Epoch [1/40], iter[2500/6563], d_out_real: 0.2952, g_out_fake: 1.3717\n",
      "Epoch [1/40], iter[2600/6563], d_out_real: 1.1252, g_out_fake: 0.4345\n",
      "Epoch [1/40], iter[2700/6563], d_out_real: 0.6980, g_out_fake: 1.1443\n",
      "Epoch [1/40], iter[2800/6563], d_out_real: 0.1441, g_out_fake: 1.2074\n",
      "Epoch [1/40], iter[2900/6563], d_out_real: 1.0948, g_out_fake: -0.1647\n",
      "Epoch [1/40], iter[3000/6563], d_out_real: 0.8541, g_out_fake: 0.9107\n",
      "Epoch [1/40], iter[3100/6563], d_out_real: 1.4307, g_out_fake: 0.8326\n",
      "Epoch [1/40], iter[3200/6563], d_out_real: 0.6578, g_out_fake: 0.9375\n",
      "Epoch [1/40], iter[3300/6563], d_out_real: 0.7210, g_out_fake: 0.5678\n",
      "Epoch [1/40], iter[3400/6563], d_out_real: 1.0121, g_out_fake: 0.4509\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 40\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    for idx, (images, _) in enumerate(train_loader):\n",
    "        \n",
    "        # The last batch hasn't the same batch size so skip it\n",
    "        bs, *_ = images.shape\n",
    "        if bs != batch_size:\n",
    "            continue\n",
    "            \n",
    "        images = images.to(device)\n",
    "        \n",
    "        netD.train()\n",
    "        netG.train()\n",
    "            \n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "        \n",
    "        # Train with real\n",
    "        d_out_real = netD(images)\n",
    "        # print(d_out_real.shape)\n",
    "        # print(\"ok\")\n",
    "        # \n",
    "        # Train with fake\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "        # print(noise.shape)\n",
    "        fakes = netG(noise)\n",
    "        d_out_fake = netD(fakes)\n",
    "        \n",
    "        \n",
    "        # adversial hinge loss\n",
    "        d_loss_real = nn.ReLU()(1.0 - d_out_real).mean()\n",
    "        d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        # Backward and optimize\n",
    "        netD.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "        fakes = netG(noise)\n",
    "        g_out_fake = netD(fakes)\n",
    "        \n",
    "        # Adversial hinge loss\n",
    "        g_loss = -g_out_fake.mean()\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        # print(d_loss_real.item())\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{nb_epochs}], \"\n",
    "                  f\"iter[{idx}/{len(train_loader)}], \"\n",
    "                  f\"d_out_real: {d_loss_real.item():.4f}, \"\n",
    "                  f\"g_out_fake: {g_loss.item():.4f}\")\n",
    "            \n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                              f'./x__{epoch}_epoch.png',\n",
    "                              normalize=True)\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVFvbXEMlzsP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2idc6MuP2A8a"
   },
   "outputs": [],
   "source": [
    "print(len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tRSNedExFUF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SAGAN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
