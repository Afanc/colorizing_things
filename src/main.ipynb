{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xsMPuuH5L4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import encoder as enc\n",
        "import generator as gen\n",
        "import discriminator as disc\n",
        "import STL10GrayColor as STLGray\n",
        "import utils as utls\n",
        "import losses\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import lab2rgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUcBis81-8Zr",
        "colab_type": "code",
        "outputId": "3e892a61-bd86-4bae-9eb3-decdccfdd883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#data\n",
        "transform = transforms.Compose([transforms.Resize(128)])#,\n",
        "#                                transforms.ToTensor()])\n",
        "\n",
        "# Load STL10 dataset\n",
        "stl10_trainset = STLGray.STL10GrayColor(root=\"./data\",\n",
        "                              split='train',\n",
        "                              download=True,\n",
        "                              transform=transform)\n",
        "\n",
        "#TODO\n",
        "#train+unlabeled in split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gtk1Oj45L4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "batch_size = 32\n",
        "z_dim = 128\n",
        "params_loader = {'batch_size': batch_size,\n",
        "               'shuffle': False}\n",
        "\n",
        "train_loader = DataLoader(stl10_trainset, **params_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTC2r4gf5L4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#demultiplier = dem.Demultiplier()\n",
        "#demultiplier = demultiplier.to(device)\n",
        "\n",
        "encoder = enc.Encoder(z_dim=z_dim)\n",
        "encoder = encoder.to(device)\n",
        "\n",
        "generator = gen.Generator(z_dim=z_dim)\n",
        "generator.apply(utls.weights_init)\n",
        "generator = generator.to(device)\n",
        "\n",
        "discriminator = disc.Discriminator()\n",
        "discriminator.apply(utls.weights_init)\n",
        "discriminator = discriminator.to(device)\n",
        "\n",
        "optimizer_params = {'lr': 0.0001,\n",
        "                    'betas':(0.5, 0.999)}\n",
        "\n",
        "enc_loss = nn.MSELoss()\n",
        "\n",
        "#optimizer_m = torch.optim.Adam(demultiplier.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "optimizer_e = torch.optim.Adam(encoder.parameters(), **optimizer_params)\n",
        "optimizer_g = torch.optim.Adam(generator.parameters(), **optimizer_params)\n",
        "optimizer_d = torch.optim.Adam(discriminator.parameters(), **optimizer_params)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azVgRuQDp6od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        },
        "outputId": "d13d7002-17c7-47d7-98c7-c88e14d6cb98"
      },
      "source": [
        "print(encoder)\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (conv_1_to_3): Sequential(\n",
            "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (vgg): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (31): Conv2d(512, 128, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (32): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Generator(\n",
            "  (layers): Sequential(\n",
            "    (0): ConvTranspose2d(128, 1024, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): ConvTranspose2d(64, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (16): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (layers): Sequential(\n",
            "    (0): Conv2d(2, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "    (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): LeakyReLU(negative_slope=0.2)\n",
            "    (12): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): LeakyReLU(negative_slope=0.2)\n",
            "    (15): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICjCd9RTqZrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "55b5c71c-c5fe-4499-ca19-b1ed98e67be4"
      },
      "source": [
        "n_epochs = 10\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(\"epoch :\", epoch)\n",
        "  \n",
        "    for i, (img_g, img_c) in enumerate(train_loader):\n",
        "        \n",
        "        img_g = img_g.to(device)\n",
        "        img_c = img_c.to(device)\n",
        "\n",
        "        bs, *_ = img_g.shape\n",
        "        if bs != batch_size:\n",
        "            continue\n",
        "\n",
        "\n",
        "        #######################\n",
        "        # Train Discriminator #\n",
        "        #######################\n",
        "        img_features = encoder(img_g)\n",
        "\n",
        "        img_colorized = generator(img_features.detach())\n",
        "\n",
        "        loss_d = losses.dis_loss(discriminator, img_c, img_colorized.detach())\n",
        "\n",
        "        #bp\n",
        "        discriminator.zero_grad()\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "        \n",
        "        #######################\n",
        "        # Train Generator #\n",
        "        #######################\n",
        "        \n",
        "        #img_colorized = generator(img_features) #re attach ?\n",
        "        \n",
        "        loss_g = losses.gen_loss(discriminator, img_colorized)\n",
        "        \n",
        "        #bp\n",
        "        generator.zero_grad()     \n",
        "        loss_g.backward()\n",
        "        optimizer_g.step()\n",
        "        \n",
        "        #######################\n",
        "        # Train Encoder #\n",
        "        #######################\n",
        "        \n",
        "        #TODO BETTER WAY/optimizing img_colorized without detach\n",
        "        #img_features = encoder(img_g)\n",
        "\n",
        "        img_colorized = generator(img_features)\n",
        "        \n",
        "        loss_e = enc_loss(img_colorized, img_c)\n",
        "        \n",
        "        print(\"loss encoder :\", loss_e.item())\n",
        "        #bp\n",
        "        encoder.zero_grad()\n",
        "        loss_e.backward()\n",
        "        optimizer_e.step()\n",
        "        \n",
        "        #printing shit\n",
        "        if (i%1 == 0) :\n",
        "            print(\"iteration \", i, \"out of \", len(train_loader.dataset)//batch_size,\n",
        "                  \"\\terrD : \", round(loss_d.item(),3), \"\\terrG : \", round(loss_g.item(),3))\n",
        "        \n",
        "        \n",
        "        if i%100 == 0:\n",
        "            img_display = utls.convert_lab2rgb(img_g, img_colorized.detach())\n",
        "            \n",
        "            vutils.save_image(img_display,\n",
        "                              f\"___epoch_{epoch}.png\",\n",
        "                              nrow=5,\n",
        "                              normalize=True)\n",
        "            print(\">plotted shit\")        \n",
        "        \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss encoder : 240.33721923828125\n",
            "iteration  0 out of  156 \terrD :  -2715.789 \terrG :  2469.628\n",
            ">plotted shit\n",
            "loss encoder : 132.7208709716797\n",
            "iteration  1 out of  156 \terrD :  -2719.08 \terrG :  2471.387\n",
            "loss encoder : 170.93991088867188\n",
            "iteration  2 out of  156 \terrD :  -2720.473 \terrG :  2473.179\n",
            "loss encoder : 177.8868865966797\n",
            "iteration  3 out of  156 \terrD :  -2722.609 \terrG :  2474.993\n",
            "loss encoder : 156.9547576904297\n",
            "iteration  4 out of  156 \terrD :  -2724.297 \terrG :  2476.717\n",
            "loss encoder : 206.63722229003906\n",
            "iteration  5 out of  156 \terrD :  -2725.703 \terrG :  2478.5\n",
            "loss encoder : 180.01422119140625\n",
            "iteration  6 out of  156 \terrD :  -2727.545 \terrG :  2480.249\n",
            "loss encoder : 260.9034423828125\n",
            "iteration  7 out of  156 \terrD :  -2728.448 \terrG :  2482.039\n",
            "loss encoder : 160.64605712890625\n",
            "iteration  8 out of  156 \terrD :  -2731.073 \terrG :  2483.851\n",
            "loss encoder : 197.50213623046875\n",
            "iteration  9 out of  156 \terrD :  -2733.127 \terrG :  2485.646\n",
            "loss encoder : 156.04544067382812\n",
            "iteration  10 out of  156 \terrD :  -2734.822 \terrG :  2487.468\n",
            "loss encoder : 195.08448791503906\n",
            "iteration  11 out of  156 \terrD :  -2736.641 \terrG :  2489.251\n",
            "loss encoder : 137.90750122070312\n",
            "iteration  12 out of  156 \terrD :  -2737.875 \terrG :  2490.988\n",
            "loss encoder : 147.57498168945312\n",
            "iteration  13 out of  156 \terrD :  -2740.101 \terrG :  2492.776\n",
            "loss encoder : 125.44356536865234\n",
            "iteration  14 out of  156 \terrD :  -2741.263 \terrG :  2494.547\n",
            "loss encoder : 144.4695281982422\n",
            "iteration  15 out of  156 \terrD :  -2742.215 \terrG :  2496.364\n",
            "loss encoder : 159.9174041748047\n",
            "iteration  16 out of  156 \terrD :  -2745.823 \terrG :  2498.098\n",
            "loss encoder : 205.8315887451172\n",
            "iteration  17 out of  156 \terrD :  -2746.263 \terrG :  2499.833\n",
            "loss encoder : 247.4317626953125\n",
            "iteration  18 out of  156 \terrD :  -2748.966 \terrG :  2501.578\n",
            "loss encoder : 158.7535858154297\n",
            "iteration  19 out of  156 \terrD :  -2749.911 \terrG :  2503.295\n",
            "loss encoder : 162.0387725830078\n",
            "iteration  20 out of  156 \terrD :  -2751.756 \terrG :  2505.12\n",
            "loss encoder : 193.5468292236328\n",
            "iteration  21 out of  156 \terrD :  -2753.741 \terrG :  2506.856\n",
            "loss encoder : 131.15345764160156\n",
            "iteration  22 out of  156 \terrD :  -2754.724 \terrG :  2508.629\n",
            "loss encoder : 291.96124267578125\n",
            "iteration  23 out of  156 \terrD :  -2757.248 \terrG :  2510.397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlIQhn25L45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2, figsize=(10,10))\n",
        "fig.subplots_adjust(hspace=0.3)\n",
        "\n",
        "\n",
        "axs[0].set_title(\"All Losses\")\n",
        "axs[0].set_xlabel(\"iterations\")\n",
        "axs[0].set_ylabel(\"Loss\")\n",
        "axs[0].plot(G_losses,label=\"G\")\n",
        "axs[0].plot(D_losses,label=\"D\")\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].set_title(\"After 1000 iterations\")\n",
        "axs[1].set_xlabel(\"iterations\")\n",
        "axs[1].set_ylabel(\"Loss\")\n",
        "axs[1].plot(G_losses[1000:],label=\"G\")\n",
        "axs[1].plot(D_losses[1000:],label=\"D\")\n",
        "axs[1].legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN0vP_G8OSNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}