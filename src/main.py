# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W970PbWuy9axDI-kl6JvTnCB0BjfrMH5
"""

#!/usr/bin/python

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

import demultiplier
import encoder 
import generator
import discriminator
import STL10GrayColor as STLGray
import utils as utls
import numpy as np


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#data
transform = transforms.Compose([transforms.Resize(128)])#,
#                                transforms.ToTensor()])

# Load STL10 dataset
stl10_trainset = STLGray.STL10GrayColor(root="./data",
                              split='train',
                              download=True,
                              transform=transform)

# Parameters
batch_size = 32
z_dim = 512
params_loader = {'batch_size': batch_size,
               'shuffle': False}

train_loader = DataLoader(stl10_trainset, **params_loader)

demultiplier = demultiplier.Demultiplier()
encoder = encoder.Encoder()
generator = generator.Generator()
generator.apply(utls.weights_init)

discriminator = discriminator.Discriminator()
discriminator.apply(utls.weights_init)

criterion = nn.MSELoss()
optimizer_m = torch.optim.Adam(demultiplier.parameters(), lr=0.0001, betas=(0.5, 0.999))
optimizer_e = torch.optim.Adam(encoder.parameters(), lr=0.0001, betas=(0.5, 0.999))
optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))
optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

real_label, fake_label = (1, 0)

for batch_index, (image_g, image_c) in enumerate(train_loader):

    # train discriminator with real
    print("training discriminator with real")

    discriminator.zero_grad()

    d_real_output = discriminator(image_c)

    labels = torch.full((image_c.shape[0],), real_label) #device = device

    errD_real = criterion(d_real_output, labels)
    errD_real.backward()

    # demultiply

    image_g = demultiplier(image_g)

    print('Demultiplied')
    print(image_g.shape)
    
    # generate color image

    enc_output = encoder(image_g)

    print('encoded')
    print(enc_output.shape)
    
    color_output = generator(enc_output)
    
    print('decoded')
    print(color_output.shape)

    # train discriminator with fake
    print("training discriminator with fake")

    #why detach ? https://github.com/pytorch/examples/issues/116
    d_fake_output = discriminator(color_output.detach())

    print("discriminated")
    print(d_fake_output.shape)

    labels = torch.full((image_c.shape[0],), fake_label) #device = device

    errD_real = criterion(d_fake_output, labels)
    errD_real.backward()
    
    optimizer_d.step()

    # train generator
    print("training generator")

    generator.zero_grad()

    labels.fill_(real_label)

    #this is needed because of the previous detach, line 99.
    d_fake_output = discriminator(color_output)

    errG = criterion(d_fake_output, labels)
    errG.backward()

    optimizer_g.step()

    # train demultiplier

    demultiplier.zero_grad()
    # no idea how to do this

