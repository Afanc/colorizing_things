# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W970PbWuy9axDI-kl6JvTnCB0BjfrMH5
"""

#!/usr/bin/python
import os, ssl
if (not os.environ.get('PYTHONHTTPSVERIFY', '') and
    getattr(ssl, '_create_unverified_context', None)): 

    ssl._create_default_https_context = ssl._create_unverified_context


import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torch.utils.data import DataLoader

import encoder as enc
import generator as gen
import discriminator as disc
import STL10GrayColor as STLGray
import utils as utls
import losses
import numpy as np
import matplotlib.pyplot as plt
from skimage.color import lab2rgb

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#data
transform = transforms.Compose([transforms.Resize(128)])#,
#                                transforms.ToTensor()])

# Load STL10 dataset
stl10_trainset = STLGray.STL10GrayColor(root="./data",
                              split='train',
                              download=True,
                              transform=transform)

#TODO
#train+unlabeled in split

# Parameters
batch_size = 32
z_dim = 128
params_loader = {'batch_size': batch_size,
               'shuffle': False}

train_loader = DataLoader(stl10_trainset, **params_loader)

#demultiplier = dem.Demultiplier()
#demultiplier = demultiplier.to(device)

encoder = enc.Encoder(z_dim=z_dim)
encoder = encoder.to(device)

generator = gen.Generator(z_dim=z_dim)
generator.apply(utls.weights_init)
generator = generator.to(device)

discriminator = disc.Discriminator()
discriminator.apply(utls.weights_init)
discriminator = discriminator.to(device)

optimizer_params = {'lr': 0.0001,
                    'betas':(0.5, 0.999)}

enc_loss = nn.MSELoss()

#optimizer_m = torch.optim.Adam(demultiplier.parameters(), lr=0.0001, betas=(0.5, 0.999))
optimizer_e = torch.optim.Adam(encoder.parameters(), **optimizer_params)
optimizer_g = torch.optim.Adam(generator.parameters(), **optimizer_params)
optimizer_d = torch.optim.Adam(discriminator.parameters(), **optimizer_params)

print(encoder)
print(generator)
print(discriminator)

n_epochs = 10


for epoch in range(n_epochs):
    print("epoch :", epoch)
  
    for i, (img_g, img_c) in enumerate(train_loader):
        
        img_g = img_g.to(device)
        img_c = img_c.to(device)

        bs, *_ = img_g.shape
        if bs != batch_size:
            continue


        #######################
        # Train Discriminator #
        #######################
        img_features = encoder(img_g)

        img_colorized = generator(img_features.detach())

        loss_d = losses.dis_loss(discriminator, img_c, img_colorized.detach())

        #bp
        discriminator.zero_grad()
        loss_d.backward()
        optimizer_d.step()
        
        #######################
        # Train Generator #
        #######################
        
        #img_colorized = generator(img_features) #re attach ?
        
        loss_g = losses.gen_loss(discriminator, img_colorized)
        
        #bp
        generator.zero_grad()     
        loss_g.backward()
        optimizer_g.step()
        
        #######################
        # Train Encoder #
        #######################
        
        #TODO BETTER WAY/optimizing img_colorized without detach
        #img_features = encoder(img_g)

        img_colorized = generator(img_features)
        
        loss_e = enc_loss(img_colorized, img_c)
        
        #bp
        encoder.zero_grad()
        loss_e.backward()
        optimizer_e.step()
        
        #printing shit
        if (i%1 == 0) :
            print("iteration ", i, "out of ", len(train_loader.dataset)//batch_size,
                  "\terrD : ", round(loss_d.item(),3), "\terrG : ", round(loss_g.item(),3))
        
        
        if i%100 == 0:
            img_display = utls.convert_lab2rgb(img_g, img_colorized.detach())
            
            vutils.save_image(img_display,
                              f"___epoch_{epoch}.png",
                              nrow=5,
                              normalize=True)
            print(">plotted shit")

    torch.save(generator.state_dict(), f'./_generator_epoch_{epoch}.pth')
    torch.save(discriminator.state_dict(), f'./_discriminator_epoch_{epoch}.pth')
