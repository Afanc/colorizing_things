# the 0th "slide" provides default styling for the presentation
[center]             # position of text
[white]       # default slide background
[text-align=center]
[text-color=black]
[font=Sans 28px]
[shading-opacity=0.000000] 
[duration=2.0] 	#total duration time

- [font=Monospace 50px]
<b><span size="xx-large">Colorizing Things</span></b>

<span size='xx-small'>Dariush Mollet, Anthony Gillioz</span>

- [left] [text-align=left] [font=Sans 70px]

Dataset : Cifar10 (train+unlabeled → 100'000 images)

Loss ? "Realistic colors" ? → GANs ❤️

<b>First approach :</b>

generator : autoencoder (~30 layers, z = 512)
    • encoder : vgg16 (pretrained on Imagenet)
    • custom decoder and discriminator

#but accepts 1 channel
    

- [./imgs/first_results.jpg]

- [left] [text-align=left] [font=Sans 70px]
<span size='x-small'>[Timelapse...]</span>

<b>Final approach :</b>

generator : Unet (~40 layers, z = 100)
    • encoder : vgg19 (pretrained on Imagenet)
    • self-attention layers
    • >200'000 iterations (>1 milion images)

--- [./imgs/sa_layer.png] [bottom-right] [font=Sans 20px]
Zhang et al. (2018) [https://arxiv.org/abs/1805.08318]
--- [./imgs/final.png]

-
Results:

- [./imgs/_fakes_epoch_1_iteration_10500.png]
- [./imgs/_fakes_epoch_1_iteration_11000.png]
- [./imgs/_fakes_epoch_1_iteration_12000.png]

-
What to do next ?
- 
• Train our network on another dataset
• Work with bigger images
• Train with more powerful GPU

-
Conclusion
-
• Very interesting project
• Acquire a lot of knowledge
• Good team work 

