# the 0th "slide" provides default styling for the presentation
[center]             # position of text
[white]       # default slide background
[text-align=center]
[text-color=black]
[font=Sans 28px]
[shading-opacity=0.000000] 
[duration=2.0] 	#total duration time

- [font=Monospace 50px]
<b><span size="xx-large">Colorizing Things</span></b>

<span size='xx-small'>Dariush Mollet, Anthony Gillioz</span>

- [left] [text-align=left] [font=Sans 70px]

Goal : Colorizing grayscale images
Dataset : STL10 (train+unlabeled → 100'000 images), 128x128

Loss ? "Realistic colors" ? → GANs ❤️

<b>First approach :</b>

generator : autoencoder (~30 layers, z = 512)
    • encoder : vgg16 (pretrained on Imagenet)
    • custom decoder and discriminator

#but accepts 1 channel
    
- [center][./imgs/first_results_final.jpg]

- [left] [text-align=left] [font=Sans 70px]
<span size='x-small'>[Timelapse...]</span>

<b>Final approach :</b>

generator : Unet (~40 layers, z = 512)
    • encoder : vgg19 (pretrained on Imagenet)
    • self-attention layers
    • >200'000 iterations (>1 milion images)

We ran into troubles...
    • vram...
    • oscillation, consistency
    • losses
    • vram
    • color spaces
    • decrypting arxiv papers
    • did we mention vram ?

--- [./imgs/sa_layer.png] [bottom-right] [font=Sans 20px]
Zhang et al. (2018) [https://arxiv.org/abs/1805.08318]
--- [./imgs/final.png]
#Results

- [./imgs/res_pres2.jpeg]
- [./imgs/res_pres1.jpeg]
- [./imgs/res_pres3.jpeg]

-[font=Sans 70px]
<span size='x-large'><b>What next ?</b></span>
• Train our network on another dataset
• Work with bigger images/expand network
• More testing
• <b>Train with more powerful GPU</b>

-[font=Sans 70px]
<span size='x-large'><b>Conclusion</b></span>
• Very interesting project
• It is not easy...
• Acquired a lot of knowledge
• Good team work 

-[font=Sans 50px]
<span size='xx-large'>Thank you for your (self-)attention</span>

Do you have any questions ?

<span size='x-small'>https://github.com/Afanc/colorizing_things</span>

- [selfie.png]

